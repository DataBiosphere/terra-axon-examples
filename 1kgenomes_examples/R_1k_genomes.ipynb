{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb6ae1e-d84c-4e3c-ad84-f899238338e3",
   "metadata": {},
   "source": [
    "# 1000 Genomes Single Chromosome PCA Example: Reading variant data into an R sparse matrix\n",
    "\n",
    "Adapted from:  \n",
    "http://bwlewis.github.io/1000_genomes_examples/PCA.html  \n",
    "https://github.com/bwlewis/1000_genomes_examples  \n",
    "\n",
    "## Introduction\n",
    "\n",
    "This example walks through the computation of principal components (PCA) of genomic variant data across one chromosome from 2,504 people from the [1000 genomes project](https://www.internationalgenome.org/1000-genomes-summary/). The example projects all of the variant data for one chromosome into a three-dimensional subspace, and then plots the result. \n",
    "\n",
    "The example uses:\n",
    "\n",
    "- a very simple C parsing program to efficiently read variant data into an R sparse matrix,\n",
    "- the `irlba` package to efficiently compute principal components,\n",
    "- the `threejs` package to visualize the result.\n",
    "\n",
    "This example is intended to be run in a Verily Workbench notebook cloud environment ('Jupyterlab Vertex AI Workbench instance'), using the R environment image.  You can take the defaults when creating the notebook environment, though some compute-heavy aspects of the analysis will run more quickly with additional cores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468f6cf-af46-443b-bedb-1db430b6195d",
   "metadata": {},
   "source": [
    "## Setup and configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc10f6-12bb-4413-8ed9-0d0d5f77bd08",
   "metadata": {},
   "source": [
    "Create Workbench [referenced resources](https://support.workbench.verily.com/docs/technical_reference/data_resources/) pointing to 1000 genomes data, if the resources have not already been created.\n",
    "The GCS URIs point to folders from the 1000 genomes public dataset.  It doesn't hurt to run these commands more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c32b368-70e7-4cf6-b01b-78f8680730bd",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"wb resource resolve --name vcf-20150220 || wb resource add-ref gcs-object --path gs://genomics-public-data/1000-genomes-phase-3/vcf-20150220 --name vcf-20150220\",\n",
    "       intern = TRUE)\n",
    "system(\"wb resource resolve --name 1000genomes_ftp || wb resource add-ref gcs-object --path gs://genomics-public-data/ftp-trace.ncbi.nih.gov/1000genomes/ftp --name 1000genomes_ftp\",\n",
    "       intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2515a6-5365-406c-8cc7-bc849ef0062c",
   "metadata": {},
   "source": [
    "Next, create a [controlled resource](https://support.workbench.verily.com/docs/technical_reference/data_resources/#referenced-vs-workspace-controlled-data-resources) bucket, which we'll use later to store some analysis results. It doesn't hurt to run this cell if the resource already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc913da-a63f-42af-b83c-268872469cfd",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"wb resource resolve --name workspace_files || wb resource create gcs-bucket --name=workspace_files --cloning=COPY_NOTHING --description='Bucket for data and reports'\", intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73497266-ec01-48c1-b7e0-fccb1479a661",
   "metadata": {},
   "source": [
    "Mount the new resources so that you can access the contents as if they are part of the file system.  \n",
    "Once the resources are defined for a workspace, they will be automounted for any new cloud environments that you create.  Because this cloud environment already exists, we'll run the command now so that we can access these new resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d94b4-91ad-41c2-ac9f-bebb5030ca4c",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"wb resource mount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e4605a-3a0c-4022-8ca9-302a6a03800d",
   "metadata": {},
   "source": [
    "After you've run this command, you should be able to see these new resources listed under `~/workspace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c3c099-a469-4cc8-ba83-26146ac3bcbd",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"ls -l /home/jupyter/workspace\", intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0f8e9-1bf4-4566-844c-18006f81b5b0",
   "metadata": {},
   "source": [
    "### Install some packages\n",
    "\n",
    "Install some necessary R packages. You only need to run the following two installation commands once per notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b4d2e-e832-4688-8f89-748efaf96f7b",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fast and memory efficient methods for truncated singular value decomposition and\n",
    "# principal components analysis of large sparse and dense matrices.\n",
    "install.packages(\"irlba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a565d5-148c-423a-b7ba-a58302bbf48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "require(remotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032ab6d-429c-4404-90d4-93e8818d38c4",
   "metadata": {},
   "source": [
    "We need to temporarily 'pin' the igraph package version, to avoid an issue with the latest version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cfcda3-a985-4987-868d-d5159e16eb79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_version(\"igraph\", version = \"1.6.0\", repos = \"http://cran.us.r-project.org\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460660c7-d29e-4175-b4e8-9a8846a33180",
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create interactive 3D scatter plots, network plots, and globes using the 'three.js' visualization library\n",
    "install.packages(\"threejs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58d81a-925f-4519-b8ce-ff97c060b5ab",
   "metadata": {},
   "source": [
    "Do some package imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87681e1-1c37-43a5-a89e-c71476aa3280",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(Matrix)\n",
    "library(irlba)\n",
    "library(tidyverse)\n",
    "library(threejs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21358e6-d4ba-4dc1-a0df-ffac198e4264",
   "metadata": {},
   "source": [
    "Download and compile a small program to parse VCF files. We could use R alone to read and parse the VCF file, it would just take a while longer. **You only need to run this cell once per notebook environment** (though it's harmless to run again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974458c-0b1a-4a76-83e3-7750b74a6ba0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"wget https://raw.githubusercontent.com/bwlewis/1000_genomes_examples/master/parse.c\")\n",
    "system(\"cc -O2 parse.c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e980bbb-f9a2-482f-8f82-1f9f708dbe31",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8559b59-ea71-4ce8-bc14-cde0a53ac6c7",
   "metadata": {},
   "source": [
    "All the remaining steps in this example run from R.  \n",
    "Let’s read the variant data for chromosome 20 into an R sparse matrix. Note that we only care about the variant number and sample (person) number in this exercise and ignore everything else.\n",
    "\n",
    "Note also that we're using the filepath of a file automounted from the referenced resource we set up earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ecbc64-3d83-4fcd-b9ab-e64cfc1c6f40",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "p <- pipe(\"cat /home/jupyter/workspace/vcf-20150220/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf  | sed /^#/d  | cut  -f '10-' | ./a.out | cut -f '1-2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a956977-a79f-4699-bc16-036a646feb7b",
   "metadata": {},
   "source": [
    "The next step will take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1a627-a97c-4f4d-98f0-e0e69b1593ff",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "x <- read.table(p, colClasses = c(\"integer\", \"integer\"), fill = TRUE, row.names = NULL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f43533e-4fd5-4fcf-8934-b05089e355c0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to a sparse matrix of people (rows) x variant (columns)\n",
    "chr20 <- sparseMatrix(i = x[,2], j = x[,1], x = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d545ef26-a3f4-44d8-8cda-f1760000b919",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect the dimensions of this matrix\n",
    "print(dim(chr20))\n",
    "# [1]    2504 1812841"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49a3900-6d2b-46d2-88a2-7a1c60f95f9b",
   "metadata": {},
   "source": [
    "We’ve loaded a sparse matrix with 2,504 rows (people) by 1,812,841 columns (variants). The next step computes the first three principal component vectors using the `irlba` package and plots a 3d scatterplot using the `threejs` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd8599-273b-4d5e-b1f5-e8236d20c116",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cm <- colMeans(chr20)\n",
    "p <- irlba(chr20, nv = 3, nu = 3, tol = 0.1, center = cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc70cb-f2df-49b4-a899-c0d6f64acd43",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "scatterplot3js(p$u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e671b7-5f4d-4896-95b9-b2bd9c8fc6a2",
   "metadata": {},
   "source": [
    "### Using ancillary \"superpopulation\" data\n",
    "\n",
    "The data exhibit obvious groups, and those groups correspond to ethnicities. That can be illustrated by loading ancillary data from the 1000 genomes project that identifies the “superpopulation” of each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299cdfa-0a39-4e1c-9b74-d032c5fc463e",
   "metadata": {},
   "source": [
    "Read just the header of the chromosome file to obtain the sample identifiers.  Again, we're using a file automounted from the 1000 Genomes folder we added as a referenced resource:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3cbe1-27d9-4a3b-a0da-f010d0a11271",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read just the header of the chromosome file to obtain the sample identifiers\n",
    "ids <- readLines(pipe(\"cat /home/jupyter/workspace/vcf-20150220/ALL.chr20.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf  | sed -n /^#CHROM/p | tr '\\t' '\\n' | tail -n +10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36affa-2c22-4851-8d8a-8f9b51f871a8",
   "metadata": {},
   "source": [
    "Download and parse the superpopulation data for each sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aaae94-50ca-421f-b244-2a1d5cacdda4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Download and parse the superpopulation data for each sample, order by ids\n",
    "ped <- read.table(url(\"ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/working/20130606_sample_info/20130606_g1k.ped\"),sep = \"\\t\",header = TRUE,row.names = 2)[ids,6,drop = FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d6f03-073c-4d69-9d9e-fc79fb8971ca",
   "metadata": {},
   "source": [
    "Read the subpopulation and superpopulation codes.  We're again using the path to one of the files automounted from a referenced resource we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca1652d-5fdf-4844-bbbb-8e419ce0a3ec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read the subpopulation and superpopulation codes\n",
    "\n",
    "pop <- read.table(\"/home/jupyter/workspace/1000genomes_ftp/20131219.populations.tsv\",sep = \"\\t\",header = TRUE)\n",
    "pop <- pop[1:26,]\n",
    "superPopulation <- pop[,3]\n",
    "names(superPopulation) <- pop[,2]\n",
    "superPopulation <- factor(superPopulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482a720a-a57a-4491-8728-85013798fd3f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Map sample sub-populations to super-populations\n",
    "ped$Superpopulation <- superPopulation[as.character(ped$Population)]\n",
    "\n",
    "# Plot with colors corresponding to super-populations\n",
    "N <- length(levels(superPopulation))\n",
    "scatterplot3js(p$u, col = rainbow(N)[ped$Superpopulation], size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c87de-c618-48d1-92ad-b704d0c75312",
   "metadata": {},
   "source": [
    "## Save your work\n",
    "\n",
    "Earlier in the notebook, we created a workspace GCS bucket named `workspace_files`, and mounted it to the notebook server's file system.  \n",
    "You can directly write to such buckets as if they are part of the local file system, which makes it easy to persist analysis results, data, and notebooks, and to share data across the workspace's cloud environments.\n",
    "\n",
    "The example below shows how you can save a dataframe to a `.tsv` file in that bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde6194-74b5-4340-acf4-cade06773fe3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"mkdir -p /home/jupyter/workspace/workspace_files/1kgenomes_analysis\")\n",
    "write_tsv(ped, '/home/jupyter/workspace/workspace_files/1kgenomes_analysis/ped.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4506690-d385-4c56-bc73-5d1c287aa9bf",
   "metadata": {},
   "source": [
    "If you like, you can also save your notebook(s) in progress to your workspace bucket. This is useful if you've made some modifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4a6bc-d246-429e-9be5-5ef7335efdbb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "system(\"mkdir -p /home/jupyter/workspace/workspace_files/1kgenomes_analysis/notebooks\")\n",
    "system(\"cp ./R_1k_genomes.ipynb /home/jupyter/workspace/workspace_files/1kgenomes_analysis/notebooks\", intern = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb5981-69ba-4449-bc5d-5e1b494986e5",
   "metadata": {},
   "source": [
    "While we don't show it here, note that if you've set up [GitHub integration](https://support.workbench.verily.com/docs/technical_reference/cloud_environments/git_repos_ssh_keys/) for your workspace, you can also use source control to checkpoint your work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd6f4f9-1a96-4f13-b7d5-123677dc8bb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "Copyright 2023 Verily Life Sciences LLC\n",
    "\n",
    "Use of this source code is governed by a BSD-style  \n",
    "license that can be found in the LICENSE file or at  \n",
    "https://developers.google.com/open-source/licenses/bsd"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ir",
   "name": ".m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m116"
  },
  "kernelspec": {
   "display_name": "R (Local)",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
